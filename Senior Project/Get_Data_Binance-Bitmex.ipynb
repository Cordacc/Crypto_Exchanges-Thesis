{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "import math\n",
    "import os.path\n",
    "import time\n",
    "import bitfinex\n",
    "from bitmex import bitmex\n",
    "from binance.client import Client\n",
    "from datetime import timedelta, datetime\n",
    "from dateutil import parser\n",
    "from tqdm import tqdm_notebook #(Optional, used for progress-bars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### API\n",
    "bitmex_api_key = 'zo0-MOxtkwdr1GCYuCVO_Nz-'    #Enter your own API-key here\n",
    "bitmex_api_secret = 'RnJ6bvC4-Ktvh2RLvpEmsgd7-JuwwsqoBh8hWUN0zHHYIXQu' #Enter your own API-secret here\n",
    "binance_api_key = 'ZfkfS7hX28D1anSV4YmyNuklKzahDRJb0s5SrIBVwTyEFc8VGq2FhreOXadNuvdv'    #Enter your own API-key here\n",
    "binance_api_secret = 'Q9E7f2jRof4jVk78qK6UiJaYSbgOtvK3ZAGjf6xElfidjYW4y5zBSb1sAmuHigay' #Enter your own API-secret here\n",
    "\n",
    "### CONSTANTS\n",
    "binsizes = {\"1m\": 1, \"5m\": 5, \"1h\": 60, \"1d\": 1440}\n",
    "batch_size = 750\n",
    "bitmex_client = bitmex(test=False, api_key=bitmex_api_key, api_secret=bitmex_api_secret)\n",
    "binance_client = Client(api_key=binance_api_key, api_secret=binance_api_secret)\n",
    "\n",
    "\n",
    "### FUNCTIONS\n",
    "def minutes_of_new_data(symbol, kline_size, data, source):\n",
    "    if len(data) > 0:  old = parser.parse(data[\"timestamp\"].iloc[-1])\n",
    "    elif source == \"binance\": old = datetime.strptime('1 Jan 2017', '%d %b %Y')\n",
    "    elif source == \"bitmex\": old = bitmex_client.Trade.Trade_getBucketed(symbol=symbol, binSize=kline_size, count=1, reverse=False).result()[0][0]['timestamp']\n",
    "    if source == \"binance\": new = pd.to_datetime(binance_client.get_klines(symbol=symbol, interval=kline_size)[-1][0], unit='ms')\n",
    "    if source == \"bitmex\": new = bitmex_client.Trade.Trade_getBucketed(symbol=symbol, binSize=kline_size, count=1, reverse=True).result()[0][0]['timestamp']\n",
    "    return old, new\n",
    "\n",
    "def get_all_binance(symbol, kline_size, save = False):\n",
    "    filename = '%s-%s-binance.csv' % (symbol, kline_size)\n",
    "    if os.path.isfile(filename): data_df = pd.read_csv(filename)\n",
    "    else: data_df = pd.DataFrame()\n",
    "    oldest_point, newest_point = minutes_of_new_data(symbol, kline_size, data_df, source = \"binance\")\n",
    "    delta_min = (newest_point - oldest_point).total_seconds()/60\n",
    "    available_data = math.ceil(delta_min/binsizes[kline_size])\n",
    "    if oldest_point == datetime.strptime('1 Jan 2017', '%d %b %Y'): print('Downloading all available %s data for %s. Be patient..!' % (kline_size, symbol))\n",
    "    else: print('Downloading %d minutes of new data available for %s, i.e. %d instances of %s data.' % (delta_min, symbol, available_data, kline_size))\n",
    "    klines = binance_client.get_historical_klines(symbol, kline_size, oldest_point.strftime(\"%d %b %Y %H:%M:%S\"), newest_point.strftime(\"%d %b %Y %H:%M:%S\"))\n",
    "    data = pd.DataFrame(klines, columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_av', 'trades', 'tb_base_av', 'tb_quote_av', 'ignore' ])\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'], unit='ms')\n",
    "    if len(data_df) > 0:\n",
    "        temp_df = pd.DataFrame(data)\n",
    "        data_df = data_df.append(temp_df)\n",
    "    else: data_df = data\n",
    "    data_df.set_index('timestamp', inplace=True)\n",
    "    if save: data_df.to_csv(filename)\n",
    "    print('All caught up..!')\n",
    "    return data_df\n",
    "\n",
    "def get_all_bitmex(symbol, kline_size, save = False):\n",
    "    filename = '%s-%s-bitmex.csv' % (symbol, kline_size)\n",
    "    if os.path.isfile(filename): data_df = pd.read_csv(filename)\n",
    "    else: data_df = pd.DataFrame()\n",
    "    oldest_point, newest_point = minutes_of_new_data(symbol, kline_size, data_df, source = \"bitmex\")\n",
    "    delta_min = (newest_point - oldest_point).total_seconds()/60\n",
    "    available_data = math.ceil(delta_min/binsizes[kline_size])\n",
    "    rounds = math.ceil(available_data / batch_size)\n",
    "    if rounds > 0:\n",
    "        print('Downloading %d minutes of new data available for %s, i.e. %d instances of %s data in %d rounds.' % (delta_min, symbol, available_data, kline_size, rounds))\n",
    "        for round_num in tqdm_notebook(range(rounds)):\n",
    "            time.sleep(1)\n",
    "            new_time = (oldest_point + timedelta(minutes = round_num * batch_size * binsizes[kline_size]))\n",
    "            data = bitmex_client.Trade.Trade_getBucketed(symbol=symbol, binSize=kline_size, count=batch_size, startTime = new_time).result()[0]\n",
    "            temp_df = pd.DataFrame(data)\n",
    "            data_df = data_df.append(temp_df)\n",
    "    data_df.set_index('timestamp', inplace=True)\n",
    "    if save and rounds > 0: data_df.to_csv(filename)\n",
    "    print('All caught up..!')\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 11999 minutes of new data available for BTCUSDT, i.e. 11999 instances of 1m data.\n",
      "All caught up..!\n",
      "Downloading 10837 minutes of new data available for EOSUSDT, i.e. 10837 instances of 1m data.\n",
      "All caught up..!\n",
      "Downloading 10792 minutes of new data available for ETHUSDT, i.e. 10792 instances of 1m data.\n",
      "All caught up..!\n",
      "Downloading 10770 minutes of new data available for LTCUSDT, i.e. 10770 instances of 1m data.\n",
      "All caught up..!\n",
      "Downloading 10639 minutes of new data available for NEOUSDT, i.e. 10639 instances of 1m data.\n",
      "All caught up..!\n",
      "Downloading 10602 minutes of new data available for XRPUSDT, i.e. 10602 instances of 1m data.\n",
      "All caught up..!\n",
      "Downloading 10553 minutes of new data available for IOTAUSDT, i.e. 10553 instances of 1m data.\n",
      "All caught up..!\n",
      "Downloading 163 minutes of new data available for ETHBTC, i.e. 163 instances of 1m data.\n",
      "All caught up..!\n"
     ]
    }
   ],
   "source": [
    "for i in ['BTCUSDT','EOSUSDT','ETHUSDT','LTCUSDT','NEOUSDT','XRPUSDT','IOTAUSDT','ETHBTC']:\n",
    "    get_all_binance(i, '1m', save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 2206885 minutes of new data available for XBTUSD, i.e. 2206885 instances of 1m data in 2943 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jane\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:54: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e98ec34da5b4a1e9de8875d5228b1cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2943.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All caught up..!\n",
      "Downloading 706663 minutes of new data available for ETHUSD, i.e. 706663 instances of 1m data in 943 rounds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e6b0367db646b1bff313bef526d792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=943.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All caught up..!\n",
      "Downloading 120638 minutes of new data available for ETHZ19, i.e. 120638 instances of 1m data in 161 rounds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ecada34602445dba6cd1b0ea835d8ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=161.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All caught up..!\n"
     ]
    }
   ],
   "source": [
    "for i in ['XBTUSD','ETHUSD','ETHZ19']:\n",
    "    get_all_bitmex(i, '1m', save = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
